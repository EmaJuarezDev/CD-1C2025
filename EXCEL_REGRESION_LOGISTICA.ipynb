{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmaJuarezDev/CD-1C2025/blob/main/EXCEL_REGRESION_LOGISTICA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyu6waNTbjzA"
      },
      "source": [
        "# Examen Práctico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFbITruJbjzB"
      },
      "source": [
        "#### 01-3900 | Ciencia de datos | 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHVZLGrGbjzB"
      },
      "source": [
        "Alumno: Pablo M. Ferreira"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndyVo1lgbjzB"
      },
      "source": [
        "## Enunciado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyEiWR_ObjzB"
      },
      "source": [
        "Se tienen un dataset con datos de pacientes internados en un hospital (TP_Virus_Alumnos.csv). La clase de interes (1) refiere a la presencia de un virus. El virus tiene normalmente una gravedad leve/baja y el tratamiento suele ser invasivo. Datos como nombre y apellido han sido eliminados y los valores tanto en sangre (BLD), hormonales u otros análisis sobre reactivos han sido alterados en sus valores para preservar la privacidad. Se aclara que no se ha modificado su capacidad predictiva (Si es que la tienen).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvxOznkZbjzC"
      },
      "source": [
        "Para su conocimiento: </BR>\n",
        "Datos generales de Edad, Peso y condición laboral (Activo, Pasivo etc).\n",
        "Datos medidos en hospital:</BR>\n",
        "BLD: Sangre</BR>\n",
        "LVL: Hormonales</BR>\n",
        "REC: Otros análisis</BR>\n",
        "\n",
        "Se pide obtener con los datos disponibles el mejor modelo posible que prediga la presencia o ausencia del virus.\n",
        "Dado que el tratamiento es invasivo y la gravedad es moderada se requiere \"atrapar\" tantos \"1\" como sea posible y minimizar los falsos positivos para evitar que reciban un tratamiento de estas caracteristicas personas que no presentan el virus. Intente obtener el mejor modelo que maximice la métrica que considere correspondiente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToUL6cxGbjzC"
      },
      "source": [
        "## Como desarrollar el exámen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75zCPD58bjzC"
      },
      "source": [
        "A partir del dataset realice todas las acciones para poder llegar al mejor modelo, explique brevemente en los fundamentos de sus transformaciones o acciones en general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKZz_S56bjzC"
      },
      "source": [
        "La nota derivará de: </BR>\n",
        "1.La calidad de la clasificación realizada</BR>\n",
        "2.La fundamentación de los pasos realizados</BR>\n",
        "3.Lo sencillo de llevar a producción el desarrollo</BR>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C08Mxqy-bjzD"
      },
      "source": [
        "Los docentes evaluaran su clasificador utilizando un conjunto de datos del dataset \"fuera de la caja\" (out of the box, al que usted no tiene acceso). Para minimizar la posible diferencia entre su medición y la medición del docente recuerde y aplique conceptos de test, validación cruzada y evite los errores comunes de sesgo de selección y fuga de datos (Sklearn \"10. Common pitfalls and recommended practices\" disponible en \"https://scikit-learn.org/stable/common_pitfalls.html)\"   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6dWpkL4bjzD"
      },
      "source": [
        "Al final del notebook encontrará un bloque de código que lee la muestra adicional (a la que usted no tiene acceso) si PRODUCCION==True, en caso contrario solo lee una submuestra del conjunto original para validar que el código funciona. Desarrolle el notebook como considere para finalmente asignar el mejor clasificador o pipeline que usted haya obtenido remplazando en f_clf = None, None por su clasificador o pipeline. Si no utiliza un pipeline, implemente todas las transformaciones entre esa línea y la predicción final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1kqp1CAbjzD"
      },
      "source": [
        "Persista modelos si realiza procesos que demoren (Mas de 10 minutos es mucho), alternativamente si quiere realizar búsquedas exhaustivas de hiperparametros o variables explicite el procedimiento y luego utilice los valores obtenidos para ajustar un clasificador/regresor y que los tiempos sean posibles en la corrección. Todas las herramientas vistas en clase están disponibles. Verifique que los docentes pueden ejecutar su clasificador / regresor usando el código adjunto y los datos \"fuera de la caja\" para validar la calidad su modelo.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1hxRUtPbjzD"
      },
      "source": [
        "En materiales del MIEL/GIT se adjuntan un notebooks con algunas ideas para automatizar el proceso (Pipelines/Transformadores customizados)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desarrollo"
      ],
      "metadata": {
        "id": "7jUdo04lwT_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Franxx20/ciencia-de-datos-tp-parcial/refs/heads/main/TP_Virus_Alumnos.csv\", sep=\",\")\n",
        "df = df.drop_duplicates() # Innecesario en este caso: el dataset no tiene duplicados"
      ],
      "metadata": {
        "id": "h04YheIoxFWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())  # Tenemos nulos?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGj3O-HlkibR",
        "outputId": "39ff5b9d-7f6f-4dea-df8c-6845207d873c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edad        822\n",
            "Genero     1682\n",
            "Peso          0\n",
            "Laboral       0\n",
            "hijos         0\n",
            "BLD01         0\n",
            "REC1          0\n",
            "REC2          0\n",
            "REC3          0\n",
            "REC4          0\n",
            "REC5          0\n",
            "BLD02         0\n",
            "BLD03         0\n",
            "LVL         527\n",
            "target        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((df.isnull().sum() / len(df)*100).sort_values(ascending=False)) # Porcentaje de valores nulos por atributo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVEjpaWtgdY5",
        "outputId": "9153b258-e4c7-4d2b-acdf-f3a843347664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genero     40.047619\n",
            "Edad       19.571429\n",
            "LVL        12.547619\n",
            "Laboral     0.000000\n",
            "hijos       0.000000\n",
            "BLD01       0.000000\n",
            "Peso        0.000000\n",
            "REC1        0.000000\n",
            "REC2        0.000000\n",
            "REC4        0.000000\n",
            "REC3        0.000000\n",
            "REC5        0.000000\n",
            "BLD02       0.000000\n",
            "BLD03       0.000000\n",
            "target      0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando matrices de correlación, pair-plots, etc. notamos que 'Edad' se puede imputar a partir de 'Peso' e 'hijos' (i.e.: las dos 'features' más cercanas).\n",
        "# TODO: Qué tal si imputo con KNN con 2 neighbours?\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "imputer = IterativeImputer(n_nearest_features=2)\n",
        "df['Edad'] = imputer.fit_transform(df[['Edad']])\n",
        "\n",
        "# Por otro lado, la columna 'Genero' tiene cerca de un 40% de nulos, no sería honesto utilizarla\n",
        "df = df.drop(columns=['Genero'])\n",
        "\n",
        "# Finalmente, imputo LVL con base en otros atributos, al igual que para la edad\n",
        "df['LVL'] = imputer.fit_transform(df[['LVL']])\n",
        "\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFtJ5SGwZJ83",
        "outputId": "99c0a7eb-2b4c-4884-cc59-496ad818ba7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edad       0\n",
            "Peso       0\n",
            "Laboral    0\n",
            "hijos      0\n",
            "BLD01      0\n",
            "REC1       0\n",
            "REC2       0\n",
            "REC3       0\n",
            "REC4       0\n",
            "REC5       0\n",
            "BLD02      0\n",
            "BLD03      0\n",
            "LVL        0\n",
            "target     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes) # Tipos de cada atributo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5nsrmwslEFh",
        "outputId": "89cefcda-48ff-4d84-bac6-904df701b8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edad       float64\n",
            "Peso       float64\n",
            "Laboral     object\n",
            "hijos        int64\n",
            "BLD01      float64\n",
            "REC1       float64\n",
            "REC2       float64\n",
            "REC3       float64\n",
            "REC4       float64\n",
            "REC5       float64\n",
            "BLD02      float64\n",
            "BLD03      float64\n",
            "LVL        float64\n",
            "target       int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uso one hot encoding para el atributo 'laboral'\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False, dtype=int)\n",
        "encoded_features = onehot_encoder.fit_transform(df[['Laboral']])\n",
        "feature_names = onehot_encoder.get_feature_names_out(['Laboral'])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=feature_names, index=df.index)\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "df = df.drop(['Laboral'], axis=1)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "S2bFTcAYlGIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe0b1d6-cbbc-42ea-818b-6bf6ed646b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Edad        Peso  hijos     BLD01      REC1       REC2       REC3  \\\n",
            "0   9.000000   36.410602      0  3.139714  6.929112  63.712640  73.880613   \n",
            "1  58.000000  115.507184      4  2.953914  4.660136  64.582610  73.669319   \n",
            "2  74.000000   81.249035      3  1.365200  3.005861  63.613454  75.103984   \n",
            "3  38.658082   77.985589      0  2.329285  4.344642  64.433115  73.402436   \n",
            "4   1.000000   13.446208      0 -0.062975  3.938741  65.122602  75.007982   \n",
            "\n",
            "        REC4       REC5     BLD02     BLD03             LVL  target  \\\n",
            "0  15.087239  90.400193  2.015331  1.633836       51.411632       0   \n",
            "1  14.503106  90.817947  0.973317 -0.439358  1000000.000000       0   \n",
            "2  14.077988  91.741638  3.243344  0.380413  1000000.000000       1   \n",
            "3  15.583846  91.741709  3.188290 -0.226046   227134.359847       0   \n",
            "4  16.961593  90.668625  2.729202  0.589698       21.627303       1   \n",
            "\n",
            "   Laboral_Activo  Laboral_Inactivo  Laboral_No_declara  \n",
            "0               0                 1                   0  \n",
            "1               0                 1                   0  \n",
            "2               1                 0                   0  \n",
            "3               0                 0                   1  \n",
            "4               0                 1                   0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notamos dos grandes grupos de LVL, los menores a 0.2 millones y los mayores a 0.7 millones, aplicamos binding separando en 0.5 (valor arbitrario).\n",
        "\n",
        "threshold = 0.5 * 1000000\n",
        "\n",
        "def categorize_lvl(lvl):\n",
        "  if lvl <= threshold:\n",
        "    return 'low'\n",
        "  elif lvl >= threshold:\n",
        "    return 'high'\n",
        "\n",
        "df['LVL_binding'] = df['LVL'].apply(categorize_lvl)\n",
        "df = df.drop('LVL', axis=1)\n",
        "\n",
        "# Ahora aplicamos one hot encoding al binding\n",
        "\n",
        "onehot_encoder_binding = OneHotEncoder(sparse_output=False)\n",
        "encoded_binding = onehot_encoder_binding.fit_transform(df[['LVL_binding']])\n",
        "binding_feature_names = onehot_encoder_binding.get_feature_names_out(['LVL_binding'])\n",
        "encoded_binding_df = pd.DataFrame(encoded_binding, columns=binding_feature_names, index=df.index)\n",
        "df = pd.concat([df, encoded_binding_df], axis=1)\n",
        "df = df.drop('LVL_binding', axis=1)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHwGmoCMVqmB",
        "outputId": "0ac71beb-e4f0-4701-9a0c-c0455185bd00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Edad        Peso  hijos     BLD01      REC1       REC2       REC3  \\\n",
            "0   9.000000   36.410602      0  3.139714  6.929112  63.712640  73.880613   \n",
            "1  58.000000  115.507184      4  2.953914  4.660136  64.582610  73.669319   \n",
            "2  74.000000   81.249035      3  1.365200  3.005861  63.613454  75.103984   \n",
            "3  38.658082   77.985589      0  2.329285  4.344642  64.433115  73.402436   \n",
            "4   1.000000   13.446208      0 -0.062975  3.938741  65.122602  75.007982   \n",
            "\n",
            "        REC4       REC5     BLD02     BLD03  target  Laboral_Activo  \\\n",
            "0  15.087239  90.400193  2.015331  1.633836       0               0   \n",
            "1  14.503106  90.817947  0.973317 -0.439358       0               0   \n",
            "2  14.077988  91.741638  3.243344  0.380413       1               1   \n",
            "3  15.583846  91.741709  3.188290 -0.226046       0               0   \n",
            "4  16.961593  90.668625  2.729202  0.589698       1               0   \n",
            "\n",
            "   Laboral_Inactivo  Laboral_No_declara  LVL_binding_high  LVL_binding_low  \n",
            "0                 1                   0               0.0              1.0  \n",
            "1                 1                   0               1.0              0.0  \n",
            "2                 0                   0               1.0              0.0  \n",
            "3                 0                   1               0.0              1.0  \n",
            "4                 1                   0               0.0              1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "float_cols = df.select_dtypes('float64').columns\n",
        "scaler = StandardScaler()\n",
        "df[float_cols] = scaler.fit_transform(df[float_cols])\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-19o_sLbmP9",
        "outputId": "f306f56a-08b3-4b42-bb37-701297e8face"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Edad      Peso  hijos     BLD01      REC1      REC2      REC3  \\\n",
            "0 -1.320429 -1.457972      0  1.419903  2.916859 -0.309346  0.838158   \n",
            "1  0.861135  1.608986      4  1.259974  0.644639  0.559778  0.633716   \n",
            "2  1.573483  0.280631      3 -0.107525 -1.012002 -0.408436  2.021856   \n",
            "3  0.000000  0.154092      0  0.722319  0.328693  0.410428  0.375487   \n",
            "4 -1.676602 -2.348413      0 -1.336839 -0.077788  1.099246  1.928968   \n",
            "\n",
            "       REC4      REC5     BLD02     BLD03  target  Laboral_Activo  \\\n",
            "0  0.068414  0.391485  0.664739  1.057077       0               0   \n",
            "1 -0.494157  0.802441 -0.363867 -1.024958       0               0   \n",
            "2 -0.903582  1.711104  1.876951 -0.201691       1               1   \n",
            "3  0.546690  1.711173  1.822605 -0.810737       0               0   \n",
            "4  1.873579  0.655549  1.369425  0.008487       1               0   \n",
            "\n",
            "   Laboral_Inactivo  Laboral_No_declara  LVL_binding_high  LVL_binding_low  \n",
            "0                 1                   0         -0.497767         0.497767  \n",
            "1                 1                   0          2.008973        -2.008973  \n",
            "2                 0                   0          2.008973        -2.008973  \n",
            "3                 0                   1         -0.497767         0.497767  \n",
            "4                 1                   0         -0.497767         0.497767  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = df.drop(\"target\", axis=1)\n",
        "Y = df[\"target\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify = Y, random_state=42)\n",
        "\n",
        "model = LogisticRegression(\n",
        "    penalty='l1',\n",
        "    C=0.01,\n",
        "    solver='saga'\n",
        ")\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7j0JQ4njBsS",
        "outputId": "0daa7e12-3d3d-48be-cc09-bf33a5ac9407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.80       748\n",
            "           1       0.76      0.52      0.61       512\n",
            "\n",
            "    accuracy                           0.74      1260\n",
            "   macro avg       0.74      0.70      0.71      1260\n",
            "weighted avg       0.74      0.74      0.72      1260\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intento mejorar los hiperparametros automáticamente\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': [None, 'l1', 'l2', 'elasticnet'],\n",
        "    'solver': ['saga']\n",
        "}\n",
        "\n",
        "# Grid search with cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='precision')\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pal_0LsYKwA",
        "outputId": "186df963-42af-467e-a0ca-a9963d42d5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "25 fits failed out of a total of 100.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1203, in fit\n",
            "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
            "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.73584644 0.78210429 0.74667031        nan 0.73584644 0.74483598\n",
            " 0.73713773        nan 0.73584644 0.73715638 0.73692052        nan\n",
            " 0.73584644 0.73584644 0.73584644        nan 0.73584644 0.73584644\n",
            " 0.73584644        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLSf64ttbjzD"
      },
      "source": [
        "## Evaluacion final - Docente + Alumno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCS4XxdnbjzD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "PRODUCCION = False\n",
        "best_clf = None #Asignar aqui el mejor clasificador/pipeline posible (previamente entrenado si es necesario)\n",
        "\n",
        "#Leemos el dataset de evaluación, simulando producción\n",
        "if PRODUCCION==False:\n",
        "    df = pd.read_csv(\"TP_Virus_Alumnos.csv\")\n",
        "    _, df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "else:\n",
        "    df = pd.read_csv(\"TP_Virus_Evaluacion.csv\")\n",
        "#Dividimos en target y predictoras\n",
        "\n",
        "X_prod = df.drop(\"target\", axis=1)\n",
        "y_prod = df[\"target\"]\n",
        "\n",
        "#Transformaciones en caso de no ser un pipeline completo. Preferiblemente, el mejor pipeline debe incluir todas las transformaciones necesarias.\n",
        "#Si es pipeline ejecutar el fit (tener en cuenta el tiempo). Si mediante exploración / busqueda exhaustiva se encontró el mejor clasificador\n",
        "#harcodear sus hiperparametros (Adjuntar código y explicación de como se encontró el mejor clasificador).\n",
        "\n",
        "#Evaluación final\n",
        "y_pred = best_clf.predict(X_prod)\n",
        "print(classification_report(y_prod, y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}